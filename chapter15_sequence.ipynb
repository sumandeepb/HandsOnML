{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10)) # wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # noise\n",
    "    return series[..., np.newaxis].astype(np.float32)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.020576663\n"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "mse_baseline = np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
    "print(mse_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 50)                0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 51        \n=================================================================\nTotal params: 51\nTrainable params: 51\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model_linear = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_linear.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "model_linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n219/219 [==============================] - 2s 7ms/step - loss: 0.1888 - mean_squared_error: 0.1888 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\nEpoch 2/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\nEpoch 3/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\nEpoch 4/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\nEpoch 5/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\nEpoch 6/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\nEpoch 7/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\nEpoch 8/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\nEpoch 9/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\nEpoch 10/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\nEpoch 11/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\nEpoch 12/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\nEpoch 13/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\nEpoch 14/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\nEpoch 15/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\nEpoch 16/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\nEpoch 17/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\nEpoch 18/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\nEpoch 19/20\n219/219 [==============================] - 1s 7ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\nEpoch 20/20\n219/219 [==============================] - 1s 6ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2bda63e370>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model_linear.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid), epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nsimple_rnn (SimpleRNN)       (None, None, 20)          440       \n_________________________________________________________________\nsimple_rnn_1 (SimpleRNN)     (None, None, 20)          820       \n_________________________________________________________________\nsimple_rnn_2 (SimpleRNN)     (None, 1)                 22        \n=================================================================\nTotal params: 1,282\nTrainable params: 1,282\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model_RNN = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "model_RNN.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "219/219 [==============================] - 99s 450ms/step - loss: 0.0494 - mean_squared_error: 0.0494 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2b34249f70>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model_RNN.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid), epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[ 0.02562159]\n  [ 0.2714945 ]\n  [ 0.45312944]\n  [ 0.53903043]\n  [ 0.5427865 ]\n  [ 0.50290084]\n  [ 0.41822007]\n  [ 0.27325052]\n  [ 0.11954144]\n  [-0.012418  ]]]\n"
    }
   ],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model_RNN.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]\n",
    "\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nsimple_rnn_3 (SimpleRNN)     (None, None, 20)          440       \n_________________________________________________________________\nsimple_rnn_4 (SimpleRNN)     (None, 20)                820       \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                210       \n=================================================================\nTotal params: 1,470\nTrainable params: 1,470\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/10\n219/219 [==============================] - 66s 303ms/step - loss: 0.0827 - mean_squared_error: 0.0827 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\nEpoch 2/10\n219/219 [==============================] - 68s 309ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0246 - val_mean_squared_error: 0.0246\nEpoch 3/10\n219/219 [==============================] - 67s 304ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\nEpoch 4/10\n219/219 [==============================] - 66s 302ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\nEpoch 5/10\n219/219 [==============================] - 66s 302ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\nEpoch 6/10\n219/219 [==============================] - 65s 299ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\nEpoch 7/10\n219/219 [==============================] - 65s 296ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\nEpoch 8/10\n219/219 [==============================] - 68s 311ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\nEpoch 9/10\n219/219 [==============================] - 68s 312ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\nEpoch 10/10\n219/219 [==============================] - 68s 308ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2ad9a8f5e0>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model_RNN = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_RNN.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "model_RNN.summary()\n",
    "\n",
    "model_RNN.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n219/219 [==============================] - 66s 303ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\nEpoch 2/10\n219/219 [==============================] - 66s 300ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\nEpoch 3/10\n219/219 [==============================] - 64s 290ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\nEpoch 4/10\n219/219 [==============================] - 64s 294ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\nEpoch 5/10\n219/219 [==============================] - 64s 291ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\nEpoch 6/10\n219/219 [==============================] - 65s 295ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\nEpoch 7/10\n219/219 [==============================] - 65s 297ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\nEpoch 8/10\n219/219 [==============================] - 66s 300ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\nEpoch 9/10\n219/219 [==============================] - 65s 297ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\nEpoch 10/10\n219/219 [==============================] - 65s 298ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2ad8071bb0>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model_RNN.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.02828513 0.26666346 0.41556624 0.51363164 0.5398246  0.5215579\n  0.37539163 0.31676355 0.26437658 0.17922427]]\n"
    }
   ],
   "source": [
    "Y_pred = model_RNN.predict(X_new)\n",
    "\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bithandsonmlconda23b04c2097f7484db9019fc72e06cb0e",
   "display_name": "Python 3.8.2 64-bit ('handsonml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}